/** @type {Service[]} */
export const services = [
    {
        slug: 'ai-strategy',
        title: 'AI Strategy & Transformation Design',
        tagline: 'Turn AI ambition into a roadmap that sticks.',
        description: 'We assess your business model, identify high-value AI opportunities, and design a phased transformation roadmap aligned to your risk appetite and operating model.',
        icon: 'Compass',
        deliverables: [
            'AI opportunity landscape assessment',
            'Use-case prioritisation matrix (value × feasibility)',
            'Phased transformation roadmap (12–18 months)',
            'Stakeholder alignment workshop outputs',
            'Build vs buy vs partner recommendation',
        ],
        workflow: [
            'Discovery: stakeholder interviews + data landscape audit',
            'Opportunity mapping: value, feasibility, risk scoring',
            'Roadmap design: phased initiatives with clear owners',
            'Alignment: executive workshop + sign-off artefacts',
        ],
        pitfalls: [
            'Pilots that never reach production',
            'Strategy disconnected from engineering realities',
            'Missing data readiness assessment before committing',
        ],
    },
    {
        slug: 'knowledge-ai-rag',
        title: 'Knowledge AI & Enterprise Search (RAG)',
        tagline: 'Your data. Answerable. Citable. Reliable.',
        description: 'We design and build retrieval-augmented generation (RAG) systems that surface accurate, sourced answers from your document corpus — at production quality.',
        icon: 'Database',
        deliverables: [
            'Data ingestion + chunking pipeline',
            'Embedding strategy and vector store setup',
            'Retrieval quality evaluation framework',
            'Hallucination guardrails + citation layer',
            'Deployed knowledge assistant (API or UI)',
        ],
        workflow: [
            'Data audit: format, volume, sensitivity classification',
            'Chunking + embedding strategy design',
            'Retrieval tuning: hybrid search, reranking',
            'Evaluation: recall, precision, faithfulness benchmarks',
            'Deploy + monitor: drift detection, feedback loop',
        ],
        pitfalls: [
            'Ignoring chunking quality — a common cause of hallucination',
            'No evaluation framework leads to silent degradation',
            'Storing sensitive data in embeddings without access controls',
        ],
    },
    {
        slug: 'agentic-automation',
        title: 'Agentic Automation & Workflow Orchestration',
        tagline: 'Multi-step work done by AI. Reliably.',
        description: 'We design, build, and operationalise agentic AI systems that chain reasoning, tool use, and API integrations to automate complex multi-step business workflows.',
        icon: 'GitBranch',
        deliverables: [
            'Agent architecture design document',
            'Tool/API integration layer',
            'Orchestration pipeline (LangChain / custom)',
            'Human-in-the-loop checkpoints',
            'Observability + retry/fallback logic',
        ],
        workflow: [
            'Workflow decomposition: identify steps, tools, decision points',
            'Agent design: planner, executor, memory, tools',
            'Integration: connect to your APIs, databases, SaaS tools',
            'Safety: human review gates, confidence thresholds',
            'Deploy + monitor: trace logs, failure alerts',
        ],
        pitfalls: [
            'Agents with no fallback when tool calls fail',
            'Unbounded loops burning tokens and API credits',
            'Missing human-in-the-loop on high-stakes decisions',
        ],
    },
    {
        slug: 'ai-product-design',
        title: 'AI Product Design (UX for AI)',
        tagline: 'AI features people actually trust and use.',
        description: 'We design AI-native product experiences — from disclosure patterns to prompt UX to output presentation — that earn user trust and drive adoption.',
        icon: 'Layers',
        deliverables: [
            'AI feature UX audit report',
            'Disclosure + transparency design patterns',
            'Prompt UI component library',
            'Output presentation design (cards, citations, confidence)',
            'User testing protocol for AI features',
        ],
        workflow: [
            'Audit: review existing AI touchpoints for trust gaps',
            'Design: transparency patterns, loading states, error UX',
            'Prototype: interactive demos for user testing',
            'Test: qualitative sessions; measure trust and task success',
            'Iterate: refine based on findings',
        ],
        pitfalls: [
            'Presenting AI output without confidence signals or citations',
            'Hiding AI involvement from users — erodes trust when discovered',
            'Over-promising outputs that the model cannot consistently deliver',
        ],
    },
    {
        slug: 'mlops-reliability',
        title: 'MLOps, Reliability & Evaluation Engineering',
        tagline: 'AI that holds up in production. Not just in demos.',
        description: 'We instrument your AI pipelines with evaluation frameworks, monitoring, guardrails, and CI cadences to keep models reliable as your data and usage evolve.',
        icon: 'Activity',
        deliverables: [
            'Evaluation framework (automated + human-in-loop)',
            'Model monitoring dashboard',
            'Drift detection + alerting setup',
            'Guardrail implementation (input/output filtering)',
            'CI/CD integration for model updates',
        ],
        workflow: [
            'Define success: latency, accuracy, faithfulness, safety metrics',
            'Build evals: unit tests for LLM outputs, regression suites',
            'Instrument: logging, tracing, dashboards',
            'Guardrails: prompt injection defence, output filters',
            'CI pipeline: gate deployments on eval thresholds',
        ],
        pitfalls: [
            'Deploying without any eval benchmark — "vibes-based" production',
            'No alerting for model drift after vendor updates',
            'Guardrails bolted on after launch instead of designed in',
        ],
    },
    {
        slug: 'responsible-ai-governance',
        title: 'Responsible AI, Governance & Compliance',
        tagline: 'Faster AI. Fewer surprises. Clearer accountability.',
        description: 'We design governance frameworks, risk controls, and compliance artefacts that make responsible AI a process — not an afterthought.',
        icon: 'Shield',
        deliverables: [
            'AI acceptable use policy',
            'Risk register (by use case)',
            'Model metadata documentation',
            'Data handling + retention policy',
            'AI disclosure templates',
        ],
        workflow: [
            'Map: inventory AI use cases and their risk profiles',
            'Govern: draft policies, roles, escalation paths',
            'Measure: define metrics for bias, fairness, accuracy',
            'Manage: incident response playbook + review cadence',
        ],
        pitfalls: [
            'Generic policies not tailored to specific AI use cases',
            'No documented model limitations communicated to users',
            'Compliance treated as checkbox rather than ongoing practice',
        ],
    },
    {
        slug: 'ai-content-enablement',
        title: 'AI Content Systems & Enablement',
        tagline: 'Operationalise AI across your teams — safely.',
        description: 'We build playbooks, prompt libraries, internal training programmes, and content systems that drive durable AI adoption across your organisation.',
        icon: 'BookOpen',
        deliverables: [
            'Role-based prompt playbook library',
            'AI content workflow design',
            'Internal training materials',
            'Adoption measurement framework',
            'AI style guide + disclosure standards',
        ],
        workflow: [
            'Audit: where is AI already in use? What are the gaps?',
            'Design: playbooks by role, workflow integrations',
            'Build: prompt library, templates, training modules',
            'Enable: workshops, onboarding, champions programme',
            'Measure: adoption, output quality, time saved',
        ],
        pitfalls: [
            'One-size-fits-all rollout ignoring role-specific needs',
            'No quality bar for AI-generated outputs going to customers',
            'Missing governance around what can be AI-assisted externally',
        ],
    },
]
